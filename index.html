<!doctype html>
<html>

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

	<title>reveal.js</title>

	<link rel="stylesheet" href="css/reveal.css">
	<link rel="stylesheet" href="css/custom.css">
	<link rel="stylesheet" href="css/theme/black.css">

	<!-- Theme used for syntax highlighting of code -->
	<link rel="stylesheet" href="lib/css/zenburn.css">

	<!-- Printing and PDF exports -->
	<script>
		var link = document.createElement('link');
		link.rel = 'stylesheet';
		link.type = 'text/css';
		link.href = window.location.search.match(/print-pdf/gi) ? 'css/print/pdf.css' : 'css/print/paper.css';
		document.getElementsByTagName('head')[0].appendChild(link);
	</script>
</head>

<body>
	<div class="reveal">
		<!-- Any section element inside of this container is displayed as a slide -->
		<div class="slides">
			<section>
				<h2>The smart shopping basket</h1>
					<h4>A Case Study with deep learning, Intel Movidius and AWS</h3>
			</section>

			<section>
				<img width="600" height="310" data-src="img/tweet.png">
			</section>
			<section data-background="#FFFFFF">
				<img width="900" height="490" data-src="img/movidius_raspberry.png">
			</section>
			<section>
				<h3>Bariers to moving AI to the Edge:</h3>
				<ul>
					<li>
						<div class="small">
							<p class="fragment">Model size<p>
						</div>
					</li>
					<li>
						<div class="small">
							<p class="fragment">Insufficient computing power<p>
						</div>
					</li>
					<li>
						<div class="small">
							<p class="fragment">Large power needs<p>
						</div>
					</li>
					<li>
						<div class="small">
							<p class="fragment">Low efficiency of simple models<p>
						</div>
					</li>
				</ul>
			</section>
			<section data-background="#FFFFFF">
				<h3>Intel® Movidius™ Neural Compute Stick</h3>
				<div>
					<div class="leftContent2">
						<img width="420" height="320" data-src="img/movidius.png">
					</div>
					<div class="rightContent2">
						<p>This tiny, fanless, deep learning device allows you to learn AI programming at the edge.</p>
					</div>
				</div>
				<aside class="notes">
					Move computting from the cloud to the edge
				</aside>
			</section>
			<section data-background="#053d6f">
				<h3>Intel® Movidius™ Myriad™ 2<br>Vision Processing Unit (VPU)﻿﻿</h3>
				<div>
					<div class="leftContent2">
						<div class="small">
							<p>
								As the industry's first always-on vision processor, this VPU delivers high-performance machine vision and visual awareness in severely power-constrained environments.
							</p>
						</div>
					</div>
					<div class="rightContent2">
						<img width="420" height="210" data-src="img/movidius_inside.png">
					</div>
				</div>
			</section>
			<section data-background="#053d6f">
				<h3>Intel® Movidius™ NCS - Key Features</h3>
				<ul>
					<li>
						<div class="small">
							<p class="fragment">An ultra-low power design<p>
						</div>
					</li>
					<li>
						<div class="small">
							<p class="fragment">Unique design for vision and AI workloads<p>
						</div>
					</li>
					<li>
						<div class="small">
							<p class="fragment">12 programmable SHAVE cores<p>
						</div>
					</li>
					<li>
						<div class="small">
							<p class="fragment">A small-area footprint<p>
						</div>
					</li>
					<li>
						<div class="small">
							<p class="fragment">Supported frameworks: TensorFlow*, Caffe*<p>
						</div>
					</li>
					<li>
						<div class="small">
							<p class="fragment">Real-time on device inference – Cloud connectivity not required<p>
						</div>
					</li>
					<li>
						<div class="small">
							<p class="fragment">The ability to run multiple devices on the same platform to scale performance<p>
						</div>
					</li>
				</ul>
				<aside class="notes">
					An ultra-low power design - For mobile and connected devices where battery life is critical, Myriad 2 provides a way to combine advanced vision applications in a low power profile. Intel's Movidius™ Myriad™ 2 VPU delivers vision capabilities to
					classes of devices previously unable to perform such demanding vision tasks.
					Unique design for vision and AI workloads - Featuring 12 VLIW programmable SHAVE cores, dedicated vision accelerators and 2 CPUS, all connected by an intelligent memory fabric, Intel's Movidius™ Myriad™ 2 VPU is a fully functional vision SoC
					designed for high performance at ultra-low power. The highly parallel design and optimizations for sparse data structures make Myriad VPUs well suited to deep neural network applications and other modern vision workloads.
					12 programmable SHAVE cores - The flexibility for developers to implement differentiated and proprietary applications is fundamental to Intel® Movidius™ Myriad™ 2 VPUs. Our optimized software libraries give device manufacturers the ability to
					run custom and proprietary operations on the 12 high performance SHAVE cores.
					A small-area footprint - To conserve space inside mobile, wearable, and embedded devices, Intel's Movidius™ Myriad™ 2 was designed with a very small footprint that can easily be integrated into existing products.
				</aside>
			</section>
			<section data-background="#053d6f">
				<h3>Intel® Movidius™ NCS - Key Capabilities</h3>
				<div class="small">
					<p class="fragment">Typical use cases:<p>
				</div>
				<div class="leftContent2">
					<ul>
						<li>
							<div class="small">
								<p class="fragment">Smart home assistant<p>
							</div>
						</li>
						<li>
							<div class="small">
								<p class="fragment">Robot<p>
							</div>
						</li>
						<li>
							<div class="small">
								<p class="fragment">Smart mirror<p>
							</div>
						</li>
						<li>
							<div class="small">
								<p class="fragment">Smart drones<p>
							</div>
						</li>
					</ul>
					<div class="small">
						<p class="fragment">Key Capabiities:<p>
					</div>
					<ul>
						<li>
							<div class="small">
								<p class="fragment">Object detection<p>
							</div>
						</li>
						<li>
							<div class="small">
								<p class="fragment">Object classification<p>
							</div>
						</li>
						<li>
							<div class="small">
								<p class="fragment">Facial recognition<p>
							</div>
						</li>
						<li>
							<div class="small">
								<p class="fragment">Natural Language Processing<p>
							</div>
						</li>
					</ul>
				</div>
				<div class="rightContent2">
					<img width="490" height="330" data-src="img/shark_spotter.jpg">
				</div>
			</section>
			<section data-transition="none">
				<h3>How does the YOLO work?</h3>
				<div>
					<div class="leftContent2">
						<img width="420" height="420" data-src="img/products.jpg">
					</div>
					<div class="rightContent2">
						<p>The original image</p>
					</div>
				</div>
			</section>
			<section data-transition="none">
				<h3>How does the YOLO work?</h3>
				<div>
					<div class="leftContent2">
						<img width="420" height="420" data-src="img/products_grid.jpg">
					</div>
					<div class="rightContent2">
						<p>The image is splitted into a grid</p>
					</div>
				</div>
			</section>
			<section data-transition="none">
				<h3>How does the YOLO work?</h3>
				<div>
					<div class="leftContent2">
						<img width="420" height="420" data-src="img/products_oshee_red.jpg">
					</div>
					<div class="rightContent2">
						<p>Each cell products anchor boxes and the likelihood P(Object)</p>
					</div>
				</div>
			</section>
			<section data-transition="none">
				<h3>How does the YOLO work?</h3>
				<div>
					<div class="leftContent2">
						<img width="420" height="420" data-src="img/products_oshee_bound.jpg">
					</div>
					<div class="rightContent2">
						<p>Each cell products anchor boxes and the likelihood P(Object)</p>
					</div>
				</div>
			</section>
			<section data-transition="none">
				<h3>How does the YOLO work?</h3>
				<div>
					<div class="leftContent2">
						<img width="420" height="420" data-src="img/products_empty_red.jpg">
					</div>
					<div class="rightContent2">
						<p>Each cell products anchor boxes and the likelihood P(Object)</p>
					</div>
				</div>
			</section>
			<section data-transition="none">
				<h3>How does the YOLO work?</h3>
				<div>
					<div class="leftContent2">
						<img width="420" height="420" data-src="img/products_empty_bound.jpg">
					</div>
					<div class="rightContent2">
						<p>Each cell products anchor boxes and the likelihood P(Object)</p>
					</div>
				</div>
			</section>
			<section data-transition="none">
				<h3>How does the YOLO work?</h3>
				<div>
					<div class="leftContent2">
						<img width="420" height="420" data-src="img/products_empty_bound_grid.jpg">
					</div>
					<div class="rightContent2">
						<p>Each cell products anchor boxes and the likelihood P(Object)</p>
					</div>
				</div>
			</section>
			<section data-transition="none">
				<h3>How does the YOLO work?</h3>
				<div>
					<div class="leftContent2">
						<img width="420" height="420" data-src="img/products_boundes.jpg">
					</div>
					<div class="rightContent2">
						<p>Each cell products anchor boxes and the likelihood P(Object)</p>
					</div>
				</div>
			</section>
			<section data-transition="none">
				<h3>How does the YOLO work?</h3>
				<div>
					<div class="leftContent2">
						<img width="420" height="420" data-src="img/products_grid.jpg">
					</div>
					<div class="rightContent2">
						<p>Each cell also predicts a probability of belonging to a given class</p>
					</div>
				</div>
			</section>
			<section data-transition="none">
				<h3>How does the YOLO work?</h3>
				<div>
					<div class="leftContent2">
						<img width="420" height="420" data-src="img/products_boundes.jpg">
					</div>
					<div class="rightContent2">
						<img width="420" height="420" data-src="img/products_grid_color.jpg">
					</div>
				</div>
			</section>
			<section data-transition="none">
				<h3>How does the YOLO work?</h3>
				<div>
					<div class="leftContent2">
						<img width="420" height="420" data-src="img/products_boundes_color.jpg">
					</div>
					<div class="rightContent2">
						<p>Then we multiply anchor boxes times class predictions</p>
					</div>
				</div>
			</section>
			<section data-transition="none">
				<h3>How does the YOLO work?</h3>
				<div>
					<div class="leftContent2">
						<img width="420" height="420" data-src="img/products_result_color.jpg">
					</div>
					<div class="rightContent2">
						<p>In the last step, the threshold is applied</p>
					</div>
				</div>
		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
				dependencies: [{
						src: 'plugin/markdown/marked.js'
					},
					{
						src: 'plugin/markdown/markdown.js'
					},
					{
						src: 'plugin/notes/notes.js',
						async: true
					},
					{
						src: 'plugin/highlight/highlight.js',
						async: true,
						callback: function() {
							hljs.initHighlightingOnLoad();
						}
					}
				]
			});
		</script>
</body>

</html>
